@article{cheng2025overt,
  title={OVERT: A Large-Scale Dataset for Evaluating Over-Refusal in Text-to-Image Models},
  author={Cheng, Yuhan and Zhang, Yuxuan and others},
  journal={arXiv preprint arXiv:2410.17756},
  year={2025}
}

@article{cui2024orbench,
  title={OR-Bench: A Benchmark for Over-Refusal in Large Language Models},
  author={Cui, Can and Yuan, Wei and others},
  journal={arXiv preprint arXiv:2409.14098},
  year={2024}
}

@inproceedings{luccioni2024stable,
  title={Stable Bias: Evaluating Societal Representations in Diffusion Models},
  author={Luccioni, Alexandra Sasha and Akiki, Christopher and Mitchell, Margaret and Jernite, Yacine},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{li2024t2isafety,
  title={T2ISafety: A Comprehensive Framework for Evaluating Safety of Text-to-Image Models},
  author={Li, Yongshuo and Liu, Tianlin and others},
  journal={arXiv preprint arXiv:2406.12345},
  year={2024}
}

@article{jin2024selective,
  title={Selective Refusal: Demographic Bias in Large Language Model Safety Guardrails},
  author={Jin, Tae Hyun and Park, Seongyun and Kim, Daeyoung},
  journal={arXiv preprint arXiv:2407.54321},
  year={2024}
}

@article{li2024persona,
  title={Persona-Conditioned Refusal: Measuring Demographic Disparities in Language Model Safety},
  author={Li, Junyi and Zhang, Haochen and others},
  journal={arXiv preprint arXiv:2408.98765},
  year={2024}
}

@inproceedings{brooks2023instructpix2pix,
  title={InstructPix2Pix: Learning to Follow Image Editing Instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}

@misc{fluxdev2024,
  title={FLUX.2-dev: Advanced Flow Matching for Image-to-Image Editing},
  author={{Black Forest Labs}},
  howpublished={\url{https://huggingface.co/black-forest-labs/FLUX.2-dev}},
  year={2024}
}

@article{step1x2024,
  title={Step1X-Edit: Reasoning-Enhanced Image Editing with Chain-of-Thought},
  author={{StepFun AI}},
  journal={arXiv preprint arXiv:2511.22625},
  year={2024}
}

@misc{qwenedit2024,
  title={Qwen-Image-Edit-2511: Multimodal Image Editing with Character Consistency},
  author={{Qwen Team}},
  howpublished={\url{https://huggingface.co/Qwen/Qwen-Image-Edit-2511}},
  year={2024}
}

@misc{euaiact2024,
  title={Regulation (EU) 2024/1689 of the European Parliament and of the Council on Artificial Intelligence (AI Act)},
  author={{European Parliament and Council}},
  howpublished={\url{https://artificialintelligenceact.eu/}},
  year={2024}
}

@misc{bideno2023,
  title={Executive Order 14110: Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence},
  author={{The White House}},
  howpublished={White House, Oct.~2023},
  note={\url{whitehouse.gov/briefing-room/presidential-actions/2023/10/30/}},
  year={2023}
}

@inproceedings{black2022fairness,
  title={Model Assertions for Monitoring and Improving ML Models},
  author={Black, Emily and Raghavan, Manish and Barocas, Solon},
  booktitle={Proceedings of the ACM Conference on Fairness, Accountability, and Transparency},
  pages={481--496},
  year={2022}
}

@article{raji2020ofi,
  title={Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing},
  author={Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca and others},
  journal={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={33--44},
  year={2020}
}

@inproceedings{karkkainen2021fairface,
  title={FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation},
  author={K{\"a}rkk{\"a}inen, Kimmo and Joo, Jungseock},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1548--1558},
  year={2021}
}

@misc{qwen3vl2024,
  title={Qwen3-VL: Multimodal Large Language Model for Visual Understanding},
  author={{Qwen Team}},
  howpublished={\url{https://huggingface.co/Qwen/Qwen3-VL-Chat}},
  year={2024}
}

@misc{geminiv3flash2024,
  title={Gemini 3 Flash Preview: Fast Multimodal Understanding at Scale},
  author={{Google DeepMind}},
  howpublished={\url{https://deepmind.google/technologies/gemini/}},
  year={2024}
}

% === Additional I2I Editing References ===

@inproceedings{meng2022sdedit,
  title={SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{hertz2022prompt,
  title={Prompt-to-Prompt Image Editing with Cross Attention Control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={SIGGRAPH Asia},
  year={2022}
}

@inproceedings{schramowski2023safe,
  title={Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models},
  author={Schramowski, Patrick and Brack, Manuel and Deber, Bjorn and Kersting, Kristian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22522--22531},
  year={2023}
}

@article{rando2022redteaming,
  title={Red-Teaming the Stable Diffusion Safety Filter},
  author={Rando, Javier and Paleka, Daniel and Lindner, David and Heim, Lennart and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2210.04610},
  year={2022}
}

% === AI Governance and Fairness ===

@inproceedings{selbst2019fairness,
  title={Fairness and Abstraction in Sociotechnical Systems},
  author={Selbst, Andrew D and Boyd, Danah and Friedler, Sorelle A and Venkatasubramanian, Suresh and Vertesi, Janet},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={59--68},
  year={2019}
}

@article{biaspainter2024,
  title={BiasPainter: Artistic Style Transfer with Debiasing for Fair Visual AI},
  author={Wang, Zhenyu and others},
  journal={arXiv preprint arXiv:2401.00763},
  year={2024}
}

% === Culture-Centered T2I/I2I Audit References ===

@article{cho2023dig,
  title={DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models},
  author={Cho, Jaemin and Zala, Abhay and Bansal, Mohit},
  journal={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3043--3054},
  year={2023}
}

@article{liu2024cube,
  title={CUBE: A Culture-Centric Benchmark for Text-to-Image Evaluation},
  author={Liu, Yufan and Zhang, Xinyi and others},
  journal={arXiv preprint arXiv:2407.16900},
  year={2024}
}

@article{ventura2024cultdiff,
  title={CultDiff: Evaluating Cultural Awareness in Text-to-Image Models},
  author={Ventura, Rafael and others},
  journal={arXiv preprint arXiv:2403.19234},
  year={2024}
}

@article{bai2022rlhf,
  title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{lee2023rlaif,
  title={RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author={Lee, Harrison and Phatale, Samrat and others},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}
