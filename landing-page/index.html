<!DOCTYPE html>
<html lang="ko">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Silent Discrimination: Race-Conditioned Refusal Bias in Image-to-Image Editing Models - IJCAI 2026"
    />
    <title>Silent Discrimination | IJCAI 2026</title>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <nav class="nav">
      <div class="container">
        <div class="nav-logo">R-Bias</div>
        <ul class="nav-menu">
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#findings">Findings</a></li>
          <li><a href="#framework">Framework</a></li>
          <li><a href="#resources">Resources</a></li>
        </ul>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-background"></div>
      <div class="container">
        <div class="hero-content">
          <div class="hero-badge">IJCAI 2026</div>
          <h1 class="hero-title">
            <span class="gradient-text">Silent Discrimination</span><br />
            Race-Conditioned Refusal Bias in Image-to-Image Editing Models
          </h1>
          <p class="hero-description">
            The first systematic audit revealing race-conditioned refusal bias
            and gender stereotype reinforcement in AI image editing models
          </p>
          <div class="hero-actions">
            <a href="#" class="btn btn-primary">Read Paper</a>
            <a href="#" class="btn btn-secondary">GitHub</a>
          </div>
          <div class="hero-stats">
            <div class="stat">
              <div class="stat-number">13,708</div>
              <div class="stat-label">Total Requests</div>
            </div>
            <div class="stat">
              <div class="stat-number">2.3×</div>
              <div class="stat-label">Racial Bias</div>
            </div>
            <div class="stat">
              <div class="stat-number">85%</div>
              <div class="stat-label">Gender Stereotypes</div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="abstract" class="section abstract">
      <div class="container">
        <h2 class="section-title">Abstract</h2>
        <p class="abstract-text">
          Image-to-Image (I2I) editing models process billions of requests monthly, yet their safety mechanisms and generation behaviors may impose disparate impact based on source image demographics. We present the first systematic audit of <strong>race-conditioned bias</strong> and <strong>gender stereotype reinforcement</strong> in I2I editing, evaluating three models across 13,708 total requests. Our comprehensive framework identifies four bias modalities: <em>hard refusal</em>, <em>soft erasure</em>, <em>stereotype replacement</em>, and <em>gender stereotyping</em>. Key findings: professional roles refused 2.3× more for Black faces (18.7% vs. 8.1% White); cross-cultural attire refused 3.7× more than stereotype-congruent requests; 11.3% of occupational edits exhibit racial drift toward White; and gender stereotype prompts show 84-86% adherence across models. These patterns persist in benign contexts, indicating systematic bias rather than legitimate safety measures. We release our comprehensive benchmark and VLM-based evaluation framework to support bias auditing in generative AI.
        </p>
      </div>
    </section>

    <section id="findings" class="section">
      <div class="container">
        <h2 class="section-title">Key Findings</h2>
        <div class="grid-2">
          <div class="card">
            <div class="card-icon">
              <!-- Simple SVG Icon representing Occupation -->
              <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M20 7h-9m1 10h-6m-9 0h2m-2-10h2m16 0h2m-2 10h2M4 7h16a2 2 0 012 2v8a2 2 0 01-2 2H4a2 2 0 01-2-2V9a2 2 0 012-2z"/></svg>
            </div>
            <h3>Racial Bias in Refusals</h3>
            <div class="stat-highlight">2.3× Higher for Black Faces</div>
            <p>Professional role prompts (e.g., "doctor", "executive") are refused at markedly higher rates for Black and Latino faces compared to White faces (18.7% vs 8.1%).</p>
          </div>
          <div class="card">
            <div class="card-icon">
               <!-- Simple SVG Icon for Culture -->
               <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/></svg>
            </div>
            <h3>Cultural Gatekeeping</h3>
            <div class="stat-highlight">3.7× Higher Refusal</div>
            <p>Cross-cultural clothing requests (e.g., hijab on non-Middle Eastern faces) fail significantly more often than stereotype-congruent requests, enforcing cultural essentialism.</p>
          </div>
          <div class="card">
            <div class="card-icon">
              <!-- Simple SVG Icon for Erasure -->
              <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18.36 6.64a9 9 0 1 1-12.7 12.7 9 9 0 0 1 1.7-16.7"/></svg>
            </div>
            <h3>Disability Erasure</h3>
            <div class="stat-highlight">40% Higher Erasure</div>
            <p>Disability markers (e.g., wheelchair) experience 41% higher soft erasure rates for Black faces, showing intersectional bias amplification.</p>
          </div>
          <div class="card">
            <div class="card-icon">
               <!-- Icon for Gender Stereotypes -->
               <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="8" r="4"/><path d="M20 16v2a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2v-2"/><path d="M12 12v4"/><path d="M8 16h8"/></svg>
            </div>
            <h3>Gender Stereotype Reinforcement</h3>
            <div class="stat-highlight">84-86% Adherence</div>
            <p>AI models follow gender stereotypes in 84-86% of cases when assigning male-stereotyped occupations (e.g., assigning "janitor" role to male-presenting individuals).</p>
          </div>
        </div>
      </div>
    </section>

    <section id="framework" class="section framework-section">
      <div class="container">
        <h2 class="section-title">Evaluation Framework</h2>
        <p class="section-subtitle">A systematic audit pipeline for race-conditioned bias in instruction-based editing.</p>
        
        <div class="framework-viz">
           <div class="fv-step">
              <div class="fv-box">
                 <span class="fv-label">I. Data</span>
                 <strong>FairFace</strong>
                 <small>84 Balanced Images</small>
              </div>
           </div>
           <div class="fv-arrow">→</div>
           <div class="fv-step">
              <div class="fv-box">
                 <span class="fv-label">II. Prompts</span>
                 <strong>104 Total</strong>
                 <small>Race + Gender Bias</small>
              </div>
           </div>
           <div class="fv-arrow">→</div>
           <div class="fv-step">
              <div class="fv-box">
                 <span class="fv-label">III. Models</span>
                 <strong>3 I2I Models</strong>
                 <small>FLUX, Step1X, Qwen</small>
              </div>
           </div>
           <div class="fv-arrow">→</div>
           <div class="fv-step">
              <div class="fv-box">
                 <span class="fv-label">IV. Evaluation</span>
                 <strong>4 Experiments</strong>
                 <small>Refusal, Erasure, Drift, Stereotypes</small>
              </div>
           </div>
        </div>
      </div>
    </section>

    <section id="resources" class="section">
      <div class="container text-center">
        <h2 class="section-title">Resources</h2>
        <div class="buttons-row">
            <a href="#" class="btn btn-primary big-btn">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
                Read Paper
            </a>
            <a href="#" class="btn btn-secondary big-btn">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                View Code
            </a>
            <a href="#" class="btn btn-secondary big-btn">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                Dataset
            </a>
        </div>
      </div>
    </section>

    <script src="script.js"></script>
  </body>
</html>
