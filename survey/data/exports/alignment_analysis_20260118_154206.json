{
  "timestamp": "20260118_154206",
  "overall": {
    "total_evaluations": 600,
    "unique_items": 200,
    "unique_raters": 3,
    "total_vlm_entries": 4917,
    "matched_with_vlm": 600
  },
  "by_dimension": {
    "edit_success": {
      "edited": {
        "n": 600,
        "human_mean": 4.148333333333333,
        "human_std": 1.1444054739858984,
        "vlm_mean": 4.235,
        "vlm_std": 1.1223969885918261,
        "mean_diff": -0.08666666666666667,
        "mae": 0.24666666666666667,
        "rmse": 0.496655480858378,
        "exact_agreement": 0.7533333333333333,
        "within_1_agreement": 1.0,
        "pearson_r": 0.9070940412958162,
        "pearson_p": 6.790280488853035e-227,
        "spearman_r": 0.8151246724260008,
        "spearman_p": 6.481247666751258e-144,
        "kendall_tau": 0.7839856881522171,
        "kendall_p": 3.52563246290597e-104
      },
      "preserved": {
        "n": 60,
        "human_mean": 4.3,
        "human_std": 0.9882644720249063,
        "vlm_mean": 4.45,
        "vlm_std": 0.9205976319760985,
        "mean_diff": -0.15,
        "mae": 0.21666666666666667,
        "rmse": 0.4654746681256314,
        "exact_agreement": 0.7833333333333333,
        "within_1_agreement": 1.0,
        "pearson_r": 0.8958072489781923,
        "pearson_p": 4.342041956974583e-22,
        "spearman_r": 0.7845183059851388,
        "spearman_p": 1.208779781095176e-13,
        "kendall_tau": 0.7617407223262942,
        "kendall_p": 3.6487282117873853e-10
      }
    },
    "skin_tone": {
      "edited": {
        "n": 600,
        "human_mean": 3.5283333333333333,
        "human_std": 0.9305180755304482,
        "vlm_mean": 3.485,
        "vlm_std": 0.7139852939661991,
        "mean_diff": 0.043333333333333335,
        "mae": 0.3933333333333333,
        "rmse": 0.6271629240742259,
        "exact_agreement": 0.6066666666666667,
        "within_1_agreement": 1.0,
        "pearson_r": 0.7406822378571013,
        "pearson_p": 2.2602658781215876e-105,
        "spearman_r": 0.7336289910407351,
        "spearman_p": 2.0692095178190222e-102,
        "kendall_tau": 0.6790907485049833,
        "kendall_p": 8.011776310818851e-79
      },
      "preserved": {
        "n": 60,
        "human_mean": 3.1166666666666667,
        "human_std": 1.0342737656066803,
        "vlm_mean": 3.25,
        "vlm_std": 0.698212002188447,
        "mean_diff": -0.13333333333333333,
        "mae": 0.43333333333333335,
        "rmse": 0.6582805886043833,
        "exact_agreement": 0.5666666666666667,
        "within_1_agreement": 1.0,
        "pearson_r": 0.7904720281824565,
        "pearson_p": 5.865416113296058e-14,
        "spearman_r": 0.7790973387864312,
        "spearman_p": 2.289870589736725e-13,
        "kendall_tau": 0.7244007427232017,
        "kendall_p": 1.843402177740805e-10
      }
    },
    "race_drift": {
      "edited": {
        "n": 600,
        "human_mean": 1.3416666666666666,
        "human_std": 0.7175866188520766,
        "vlm_mean": 1.13,
        "vlm_std": 0.6656575696257048,
        "mean_diff": 0.21166666666666667,
        "mae": 0.22833333333333333,
        "rmse": 0.4778423728943817,
        "exact_agreement": 0.7716666666666666,
        "within_1_agreement": 1.0,
        "pearson_r": 0.8107112876068454,
        "pearson_p": 3.6422427695234216e-141,
        "spearman_r": 0.4425713931404586,
        "spearman_p": 3.6069979244774474e-30,
        "kendall_tau": 0.4380149159480937,
        "kendall_p": 6.541316651577579e-28
      },
      "preserved": {
        "n": 60,
        "human_mean": 1.1333333333333333,
        "human_std": 0.339934634239519,
        "vlm_mean": 1.0,
        "vlm_std": 0.0,
        "mean_diff": 0.13333333333333333,
        "mae": 0.13333333333333333,
        "rmse": 0.3651483716701107,
        "exact_agreement": 0.8666666666666667,
        "within_1_agreement": 1.0,
        "pearson_r": NaN,
        "pearson_p": NaN,
        "spearman_r": NaN,
        "spearman_p": NaN,
        "kendall_tau": NaN,
        "kendall_p": NaN
      }
    },
    "gender_drift": {
      "edited": {
        "n": 600,
        "human_mean": 1.2033333333333334,
        "human_std": 0.4065983549182438,
        "vlm_mean": 1.005,
        "vlm_std": 0.07053367989832943,
        "mean_diff": 0.19833333333333333,
        "mae": 0.19833333333333333,
        "rmse": 0.44534630719624624,
        "exact_agreement": 0.8016666666666666,
        "within_1_agreement": 1.0,
        "pearson_r": 0.19700910049684814,
        "pearson_p": 1.1538809038658597e-06,
        "spearman_r": 0.1525919105093302,
        "spearman_p": 0.0001754838732880405,
        "kendall_tau": 0.15246601011379446,
        "kendall_p": 0.0001880084499785861
      },
      "preserved": {
        "n": 60,
        "human_mean": 1.25,
        "human_std": 0.4330127018922193,
        "vlm_mean": 1.0,
        "vlm_std": 0.0,
        "mean_diff": 0.25,
        "mae": 0.25,
        "rmse": 0.5,
        "exact_agreement": 0.75,
        "within_1_agreement": 1.0,
        "pearson_r": NaN,
        "pearson_p": NaN,
        "spearman_r": NaN,
        "spearman_p": NaN,
        "kendall_tau": NaN,
        "kendall_p": NaN
      }
    },
    "age_drift": {
      "edited": {
        "n": 600,
        "human_mean": 3.115,
        "human_std": 0.8593262864981304,
        "vlm_mean": 3.1,
        "vlm_std": 0.6557438524302001,
        "mean_diff": 0.015,
        "mae": 0.37166666666666665,
        "rmse": 0.609644705272396,
        "exact_agreement": 0.6283333333333333,
        "within_1_agreement": 1.0,
        "pearson_r": 0.7071898210537896,
        "pearson_p": 4.213841683257858e-92,
        "spearman_r": 0.6487769042244154,
        "spearman_p": 5.76854004932288e-73,
        "kendall_tau": 0.6100410541686319,
        "kendall_p": 6.401291260536739e-63
      },
      "preserved": {
        "n": 60,
        "human_mean": 2.8333333333333335,
        "human_std": 0.8787617550976045,
        "vlm_mean": 2.9,
        "vlm_std": 0.6244997998398398,
        "mean_diff": -0.06666666666666667,
        "mae": 0.4,
        "rmse": 0.6324555320336759,
        "exact_agreement": 0.6,
        "within_1_agreement": 1.0,
        "pearson_r": 0.6985108148203263,
        "pearson_p": 5.466912844447749e-10,
        "spearman_r": 0.6407814280666405,
        "spearman_p": 3.496795962258748e-08,
        "kendall_tau": 0.6016444310763576,
        "kendall_p": 2.3068232414593045e-07
      }
    }
  },
  "by_model": {
    "flux": {
      "n": 3000,
      "human_mean": 2.667333333333333,
      "human_std": 1.4580807781311553,
      "vlm_mean": 2.591,
      "vlm_std": 1.487184924614286,
      "mean_diff": 0.07633333333333334,
      "mae": 0.2876666666666667,
      "rmse": 0.5363456596884761,
      "exact_agreement": 0.7123333333333334,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9352084014309887,
      "pearson_p": 0.0,
      "spearman_r": 0.9311090198948279,
      "spearman_p": 0.0,
      "kendall_tau": 0.868925895783269,
      "kendall_p": 0.0
    }
  },
  "by_category": {
    "D": {
      "n": 3000,
      "human_mean": 2.667333333333333,
      "human_std": 1.4580807781311553,
      "vlm_mean": 2.591,
      "vlm_std": 1.487184924614286,
      "mean_diff": 0.07633333333333334,
      "mae": 0.2876666666666667,
      "rmse": 0.5363456596884761,
      "exact_agreement": 0.7123333333333334,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9352084014309887,
      "pearson_p": 0.0,
      "spearman_r": 0.9311090198948279,
      "spearman_p": 0.0,
      "kendall_tau": 0.868925895783269,
      "kendall_p": 0.0
    }
  },
  "by_race": {
    "Latino": {
      "n": 390,
      "human_mean": 2.6256410256410256,
      "human_std": 1.4912940429102037,
      "vlm_mean": 2.5846153846153848,
      "vlm_std": 1.4924662881625752,
      "mean_diff": 0.041025641025641026,
      "mae": 0.3333333333333333,
      "rmse": 0.5773502691896257,
      "exact_agreement": 0.6666666666666666,
      "within_1_agreement": 1.0,
      "pearson_r": 0.925495810470984,
      "pearson_p": 1.1091710321297277e-165,
      "spearman_r": 0.9271094796815624,
      "spearman_p": 1.861892288468054e-167,
      "kendall_tau": 0.8619808747343303,
      "kendall_p": 2.1908261336569036e-94
    },
    "Indian": {
      "n": 510,
      "human_mean": 2.6549019607843136,
      "human_std": 1.441175136720738,
      "vlm_mean": 2.552941176470588,
      "vlm_std": 1.4552613054458734,
      "mean_diff": 0.10196078431372549,
      "mae": 0.2980392156862745,
      "rmse": 0.5459296801661131,
      "exact_agreement": 0.7019607843137254,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9314722127332442,
      "pearson_p": 3.2011704692712573e-225,
      "spearman_r": 0.9255296806010861,
      "spearman_p": 2.196614725572168e-216,
      "kendall_tau": 0.8608076254407105,
      "kendall_p": 2.0383925371209785e-123
    },
    "SoutheastAsian": {
      "n": 390,
      "human_mean": 2.6307692307692307,
      "human_std": 1.4221965398733092,
      "vlm_mean": 2.5923076923076924,
      "vlm_std": 1.4607487745154952,
      "mean_diff": 0.038461538461538464,
      "mae": 0.23846153846153847,
      "rmse": 0.48832523840319625,
      "exact_agreement": 0.7615384615384615,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9433215007427912,
      "pearson_p": 5.932920658503978e-188,
      "spearman_r": 0.9428276901569893,
      "spearman_p": 3.040587651484424e-187,
      "kendall_tau": 0.8904770692378862,
      "kendall_p": 1.3047089793284133e-101
    },
    "EastAsian": {
      "n": 420,
      "human_mean": 2.6214285714285714,
      "human_std": 1.4282916392679477,
      "vlm_mean": 2.507142857142857,
      "vlm_std": 1.4564949539975782,
      "mean_diff": 0.11428571428571428,
      "mae": 0.3,
      "rmse": 0.5477225575051661,
      "exact_agreement": 0.7,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9312254462522022,
      "pearson_p": 2.4175594629211974e-185,
      "spearman_r": 0.9291623627904427,
      "spearman_p": 9.334737797122255e-183,
      "kendall_tau": 0.8675534002317979,
      "kendall_p": 5.041998489791858e-104
    },
    "MiddleEastern": {
      "n": 375,
      "human_mean": 2.7093333333333334,
      "human_std": 1.4360290928653068,
      "vlm_mean": 2.616,
      "vlm_std": 1.5167544296951962,
      "mean_diff": 0.09333333333333334,
      "mae": 0.30666666666666664,
      "rmse": 0.5537749241945383,
      "exact_agreement": 0.6933333333333334,
      "within_1_agreement": 1.0,
      "pearson_r": 0.933097996218945,
      "pearson_p": 9.471946489686104e-168,
      "spearman_r": 0.9264647165573567,
      "spearman_p": 2.2812534886319284e-160,
      "kendall_tau": 0.8610027605630919,
      "kendall_p": 1.145688870572863e-90
    },
    "White": {
      "n": 570,
      "human_mean": 2.6157894736842104,
      "human_std": 1.4381139541609191,
      "vlm_mean": 2.542105263157895,
      "vlm_std": 1.4817542197905278,
      "mean_diff": 0.07368421052631578,
      "mae": 0.28421052631578947,
      "rmse": 0.5331139899831832,
      "exact_agreement": 0.7157894736842105,
      "within_1_agreement": 1.0,
      "pearson_r": 0.935033880481377,
      "pearson_p": 5.974203030328997e-258,
      "spearman_r": 0.9263430894620076,
      "spearman_p": 5.136463642138889e-243,
      "kendall_tau": 0.8649882474267669,
      "kendall_p": 1.4232664365004427e-140
    },
    "Black": {
      "n": 345,
      "human_mean": 2.869565217391304,
      "human_std": 1.5558495836378632,
      "vlm_mean": 2.8086956521739133,
      "vlm_std": 1.5486075213553911,
      "mean_diff": 0.06086956521739131,
      "mae": 0.2463768115942029,
      "rmse": 0.4963635881027162,
      "exact_agreement": 0.7536231884057971,
      "within_1_agreement": 1.0,
      "pearson_r": 0.9496515266932803,
      "pearson_p": 5.950470213375056e-175,
      "spearman_r": 0.9418441969930552,
      "spearman_p": 1.6455571035246784e-164,
      "kendall_tau": 0.88476936987329,
      "kendall_p": 3.810047757823172e-89
    }
  },
  "inter_rater": {
    "edit_success": {
      "n_items": 200,
      "n_raters_per_item": 3.0,
      "pairwise_agreement": 0.605
    },
    "skin_tone": {
      "n_items": 200,
      "n_raters_per_item": 3.0,
      "pairwise_agreement": 0.4683333333333333
    },
    "race_drift": {
      "n_items": 200,
      "n_raters_per_item": 3.0,
      "pairwise_agreement": 0.6766666666666666
    },
    "gender_drift": {
      "n_items": 200,
      "n_raters_per_item": 3.0,
      "pairwise_agreement": 0.6833333333333333
    },
    "age_drift": {
      "n_items": 200,
      "n_raters_per_item": 3.0,
      "pairwise_agreement": 0.4666666666666667
    }
  }
}